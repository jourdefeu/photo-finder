import os
import cv2
import numpy as np
import traceback
from insightface.app import FaceAnalysis
from insightface.utils import face_align

# –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º CPU –¥–æ ~70%
cpu_count = max(1, int(os.cpu_count() * 0.7))
os.environ["OMP_NUM_THREADS"] = str(cpu_count)

class FaceDetector:
    def __init__(self, device="cpu", yaw_threshold=30):
        """
        RetinaFace (–∏–∑ insightface) –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü.
        –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ CPU, –µ—Å–ª–∏ device="cpu".
        """
        ctx_id = 0 if device == "cuda" else -1
        self.app = FaceAnalysis(name="buffalo_l")
        self.app.prepare(ctx_id=ctx_id)
        self.yaw_threshold = yaw_threshold
        print(f"‚úÖ FaceDetector initialized (device={device})")

    def detect_and_draw(self, input_path, output_path):
        """
        –ù–∞—Ö–æ–¥–∏—Ç –ª–∏—Ü–∞ –Ω–∞ —Ñ–æ—Ç–æ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–ø–∏—é —Å –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã–º–∏ —Ä–∞–º–∫–∞–º–∏.
        """
        img = cv2.imread(input_path)
        if img is None:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {input_path}")
            return False

        faces = self.app.get(img)
        print(f"üì∏ {os.path.basename(input_path)} ‚Üí –Ω–∞–π–¥–µ–Ω–æ {len(faces)} –ª–∏—Ü")

        # —Ä–∏—Å—É–µ–º —Ä–∞–º–∫–∏ –≤–æ–∫—Ä—É–≥ –ª–∏—Ü
        for i, face in enumerate(faces):
            x1, y1, x2, y2 = face.bbox.astype(int)
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(
                img,
                f"face {i+1}",
                (x1, y1 - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 255, 0),
                2,
            )

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ä–∞–º–∫–∞–º–∏
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        cv2.imwrite(output_path, img)
        return True

    def align_from_detected(self, input_path, output_path):
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç –ª–∏—Ü–∞ –ø–æ –ø–æ–≤–æ—Ä–æ—Ç—É –≥–æ–ª–æ–≤—ã, –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω—ã–µ –ª–∏—Ü–∞.
        """
        img = cv2.imread(input_path)
        if img is None:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {input_path}")
            return []  # return False

        faces = self.app.get(img)
        aligned_faces_info = []

        for i, face in enumerate(faces):
            # bbox –¥–ª—è –ª–∏—Ü–∞
            x1, y1, x2, y2 = face.bbox.astype(int)
            
            # –ø—Ä–æ–≤–µ—Ä—è–µ–º landmarks
            landmark = face.landmark_2d_5 if face.landmark_2d_5 is not None else None

            if landmark is not None:
                try:
                    # –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ norm_crop
                    aligned_face = face_align.norm_crop(img, landmark=landmark)
                except Exception as e:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—Ä–æ–≤–Ω—è—Ç—å –ª–∏—Ü–æ {i+1}, fallback –Ω–∞ bbox: {e}")
                    aligned_face = img[y1:y2, x1:x2]
            else:
                # fallback: –ø—Ä–æ—Å—Ç–æ crop –ø–æ bbox
                aligned_face = img[y1:y2, x1:x2]

            out_file = os.path.join(
                output_path,
                f"{os.path.splitext(os.path.basename(input_path))[0]}_{i+1}.png"
            )
            cv2.imwrite(out_file, aligned_face)
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ª–∏—Ü–æ: {out_file}")

            aligned_faces_info.append({
                "bbox": face.bbox.tolist(),
                "pose": tuple(face.pose) if face.pose is not None else (0,0,0),
                "aligned_path": out_file,
                "embedding": face.embedding
            })

        print(f"‚úÖ –í—Å–µ–≥–æ –≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω—ã—Ö –ª–∏—Ü: {len(aligned_faces_info)} –≤ {os.path.basename(input_path)}")
        return aligned_faces_info

