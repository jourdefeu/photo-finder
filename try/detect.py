import os
import cv2
import numpy as np
import traceback
from insightface.app import FaceAnalysis
from insightface.utils import face_align

# ----- –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å CPU -----

# ----- –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–æ–π—Ç–∏ –ø—É—Ç–µ–º 1) –æ–±—Ä–µ–∑–∫–∏, 2) –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è -----
# --------------- –Ω–µ —Ä—É–±–∏—Ç—å —Å—Ä–∞–∑—É landmark ---------------

class FaceDetector:
    def __init__(self, device="cpu", yaw_threshold=30):
        """
        RetinaFace (–∏–∑ insightface) –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü.
        –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ CPU, –µ—Å–ª–∏ device="cpu".
        """
        ctx_id = 0 if device == "cuda" else -1
        self.app = FaceAnalysis(name="buffalo_l")
        self.app.prepare(ctx_id=ctx_id)
        self.yaw_threshold = yaw_threshold
        print(f"‚úÖ FaceDetector initialized (device={device})")

    def detect_and_draw(self, input_path, output_path):
        """
        –ù–∞—Ö–æ–¥–∏—Ç –ª–∏—Ü–∞ –Ω–∞ —Ñ–æ—Ç–æ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–ø–∏—é —Å –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã–º–∏ —Ä–∞–º–∫–∞–º–∏.
        """
        img = cv2.imread(input_path)
        if img is None:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {input_path}")
            return False

        faces = self.app.get(img)
        print(f"üì∏ {os.path.basename(input_path)} ‚Üí –Ω–∞–π–¥–µ–Ω–æ {len(faces)} –ª–∏—Ü")

        # —Ä–∏—Å—É–µ–º —Ä–∞–º–∫–∏ –≤–æ–∫—Ä—É–≥ –ª–∏—Ü
        for i, face in enumerate(faces):
            x1, y1, x2, y2 = face.bbox.astype(int)
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(
                img,
                f"face {i+1}",
                (x1, y1 - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 255, 0),
                2,
            )

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ä–∞–º–∫–∞–º–∏
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        cv2.imwrite(output_path, img)
        return True

    def align_from_detected(self, input_path, output_path):
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç –ª–∏—Ü–∞ –ø–æ –ø–æ–≤–æ—Ä–æ—Ç—É –≥–æ–ª–æ–≤—ã, –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω—ã–µ –ª–∏—Ü–∞.
        """
        img = cv2.imread(input_path)
        if img is None:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {input_path}")
            return []  # return False

        faces = self.app.get(img)
        aligned_faces_info = []
        image_size = 112

        for i, face in enumerate(faces):
            # bbox –¥–ª—è –ª–∏—Ü–∞
            x1, y1, x2, y2 = face.bbox.astype(int)
            
            try:
                # 3D landmark 
                if hasattr(face, "landmark_3d_68") and face.landmark_3d_68 is not None:
                    lm3d = face.landmark_3d_68.astype(np.float32)
                    frontal_img = frontalize_face(img, lm3d)
                    aligned_face = frontal_img[y1:y2, x1:x2]

                # 106-—Ç–æ—á–µ—á–Ω—ã–µ landmark'–∏
                elif hasattr(face, "landmark_2d_106") and face.landmark_2d_106 is not None:
                    lm = face.landmark_2d_106.astype(np.float32)
                    landmark_5 = np.array([
                        lm[38],   # –ª–µ–≤—ã–π –≥–ª–∞–∑
                        lm[88],   # –ø—Ä–∞–≤—ã–π –≥–ª–∞–∑
                        lm[86],   # –Ω–æ—Å
                        lm[52],   # –ª–µ–≤—ã–π —É–≥–æ–ª —Ä—Ç–∞
                        lm[61]    # –ø—Ä–∞–≤—ã–π —É–≥–æ–ª —Ä—Ç–∞
                    ], dtype=np.float32)
                    aligned_face = face_align.norm_crop(img, landmark_5, image_size=image_size)

                # –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ InsightFace
                elif hasattr(face, "aligned_face") and face.aligned_face is not None:
                    aligned_face = face.aligned_face
 
                else:
                    # fallback: –ø—Ä–æ—Å—Ç–æ crop –ø–æ bbox
                    aligned_face = img[y1:y2, x1:x2]

            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—Ä–æ–≤–Ω—è—Ç—å –ª–∏—Ü–æ {i+1}, fallback –Ω–∞ bbox: {e}")
                aligned_face = img[y1:y2, x1:x2]

            out_file = os.path.join(
                output_path,
                f"{os.path.splitext(os.path.basename(input_path))[0]}_{i+1}.png"
            )
            cv2.imwrite(out_file, aligned_face)
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ª–∏—Ü–æ: {out_file}")

            aligned_faces_info.append({
                "photo_id": os.path.splitext(os.path.basename(input_path))[0],
                "bbox": face.bbox.tolist(),
                "pose": tuple(face.pose) if face.pose is not None else (0,0,0),
                "aligned_path": out_file,
                "embedding": face.embedding
            })

        print(f"‚úÖ –í—Å–µ–≥–æ –≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω—ã—Ö –ª–∏—Ü: {len(aligned_faces_info)} –≤ {os.path.basename(input_path)}")
        return aligned_faces_info

def frontalize_face(img, landmarks_3d):
    """
    –ü—Ä–æ—Å—Ç–µ–π—à–∞—è 3D-—Ñ—Ä–æ–Ω—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ landmark_3d_68.
    –ù–µ —Å—Ç—Ä–æ–∏—Ç –ø–æ–ª–Ω—É—é 3D-–º–æ–¥–µ–ª—å, –Ω–æ –∫–æ–º–ø–µ–Ω—Å–∏—Ä—É–µ—Ç –ø–æ–≤–æ—Ä–æ—Ç –≥–æ–ª–æ–≤—ã.
    """
    # –¶–µ–Ω—Ç—Ä –ª–∏—Ü–∞ (—Å—Ä–µ–¥–Ω–µ–µ –ø–æ x,y)
    center = np.mean(landmarks_3d[:, :2], axis=0)

    # –û—Å–∏ –≥–æ–ª–æ–≤—ã
    x_axis = landmarks_3d[45][:3] - landmarks_3d[36][:3]  # –æ—Ç –ª–µ–≤–æ–≥–æ –¥–æ –ø—Ä–∞–≤–æ–≥–æ –≥–ª–∞–∑–∞
    x_axis /= np.linalg.norm(x_axis)
    y_axis = landmarks_3d[30][:3] - landmarks_3d[8][:3]   # –æ—Ç –ø–æ–¥–±–æ—Ä–æ–¥–∫–∞ –∫ –Ω–æ—Å—É
    y_axis /= np.linalg.norm(y_axis)
    z_axis = np.cross(x_axis, y_axis)
    R = np.stack([x_axis, y_axis, z_axis], axis=1)

    # –ü—Ä–æ—Å—Ç–µ–π—à–∞—è "—Ñ—Ä–æ–Ω—Ç–∞–ª–∏–∑–∞—Ü–∏—è": –ø—Ä–∏–º–µ–Ω–∏–º –ø–æ–≤–æ—Ä–æ—Ç –æ–±—Ä–∞—Ç–Ω–æ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    # (—É–ø—Ä–æ—â—ë–Ω–Ω–æ —á–µ—Ä–µ–∑ warpAffine; –¥–ª—è –∏–¥–µ–∞–ª–∞ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å warpPerspective)
    h, w = img.shape[:2]
    warp_mat = cv2.getRotationMatrix2D(tuple(center), 0, 1.0)
    aligned = cv2.warpAffine(img, warp_mat, (w, h), flags=cv2.INTER_LINEAR)

    return aligned

if __name__ == "__main__":
    detector = FaceDetector(device="cpu")

    input_dir = "try/photos/raw"
    detected_dir = "try/photos/detected"
    aligned_dir = "try/photos/aligned"

    os.makedirs(detected_dir, exist_ok=True)
    os.makedirs(aligned_dir, exist_ok=True)

    # –ø—Ä–æ—Ö–æ–¥ –ø–æ –≤—Å–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
    for filename in os.listdir(input_dir):
        if filename.lower().endswith((".jpg", ".jpeg", ".png", ".webp")):
            in_path = os.path.join(input_dir, filename)
            out_path = os.path.join(detected_dir, filename)

            # –¥–µ—Ç–µ–∫—Ü–∏—è –∏ —Ä–∞–º–∫–∏
            success = detector.detect_and_draw(in_path, out_path)
            if success:
                print(f"üíæ –§–æ—Ç–æ —Å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –ª–∏—Ü–∞–º–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {out_path}")

                # –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ª–∏—Ü
                # –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–æ—Ç–æ –±—É–¥–µ—Ç —Å–≤–æ—è –ø–æ–¥–ø–∞–ø–∫–∞ —Å –≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω—ã–º–∏ –ª–∏—Ü–∞–º–∏
                aligned_dir_for_file = os.path.join(aligned_dir, os.path.splitext(filename)[0])
                os.makedirs(aligned_dir_for_file, exist_ok=True)
                detector.align_from_detected(in_path, aligned_dir_for_file)
